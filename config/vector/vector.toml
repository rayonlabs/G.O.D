# Vector configuration for shipping training logs to remote Loki

[api]
enabled = true
address = "0.0.0.0:8686"

# -------------------------
# Sources
# -------------------------
[sources.docker_logs]
type = "docker_logs"
docker_host = "unix:///var/run/docker.sock"

include_labels = ["task_id", "hotkey", "model", "task_type"]

[sources.fastapi_logs]
type     = "http_server"
address  = "0.0.0.0:8688"   # expose 8688 if Vector runs in Docker
encoding = "json"


[sources.internal_metrics]
type = "internal_metrics"

# -------------------------
# Transforms
# -------------------------
[transforms.parse_logs]
type   = "remap"
inputs = ["docker_logs"]
source = """
# --- Normalize message so Grafana shows clean text ---
m = ""
if exists(.message) && .message != null {
  m, err = to_string(.message)
} else if exists(.log) && .log != null {
  m, err = to_string(.log)
} else if exists(.stream) && .stream != null {
  m, err = to_string(.stream)
} else {
  m = to_string!(.)
}
.message = m

# --- Default level ---
.level = "INFO"

# --- Parse '<ts> <level> <content>' if present ---
re = r'^(?P<ts>\\d{4}-\\d{2}-\\d{2}[T ]\\d{2}:\\d{2}:\\d{2}[.,]\\d{3})\\s+(?P<lvl>\\w+)\\s+(?P<content>.*)$'
if match!(.message, re) {
  caps = parse_regex!(.message, re)
  .message = to_string(caps.content)
  .level   = upcase(to_string(caps.lvl))

  ts  = to_string(caps.ts)
  fmt = "%Y-%m-%d %H:%M:%S,%3f"
  if contains(ts, "T") { fmt = "%Y-%m-%dT%H:%M:%S,%3f" }
  if contains(ts, ".") { fmt = replace(fmt, ",%3f", ".%3f") }
  .timestamp = parse_timestamp(ts, fmt) ?? now()
} else if match!(.message, r'(?i)(ERROR|WARN|WARNING|INFO|DEBUG|CRITICAL)') {
  caps2  = parse_regex!(.message, r'(?i)(ERROR|WARN|WARNING|INFO|DEBUG|CRITICAL)')
  .level = upcase(to_string(caps2[0]))
}

# --- Metadata ---
.trainer_server = get_hostname!()
.environment    = get_env_var("ENVIRONMENT") ?? "production"

# --- Docker label mapping ---
task_id_   = null
hotkey_    = null
model_     = null
task_type_ = null

# task id
if exists(.label) && exists(.label.task_id) && .label.task_id != null { task_id_ = .label.task_id }
.task_id = to_string(task_id_) ?? "unknown"

# hotkey
if exists(.label) && exists(.label.hotkey) && .label.hotkey != null { hotkey_ = .label.hotkey }
.hotkey = to_string(hotkey_) ?? "unknown"

# model
if exists(.label) && exists(.label.model) && .label.model != null { model_ = .label.model }
.model = to_string(model_) ?? "unknown"

# task_type
if exists(.label) && exists(.label.task_type) && .label.task_type != null { task_type_ = .label.task_type }
.task_type = to_string(task_type_) ?? "unknown"

# --- Counter for reduce aggregation (you use this later) ---
.count = 1

# --- Cleanup (safe) ---
del(.label_task_id)
del(.label_hotkey)
del(.label_model)
del(.label_trainer_type)
del(.label_task_type)
del(.label_expected_repo)
"""

[transforms.filter_noise]
type = "filter"
inputs = ["parse_logs"]
condition = """
m, err = to_string(.message)
!contains(m, "Downloading shards") &&
!contains(m, "Loading checkpoint shards") &&
!contains(m, "heartbeat")
"""

# --- FastAPI normalizer (host logs â†’ same fields/labels as Docker) ---
[transforms.normalize_fastapi]
type   = "remap"
inputs = ["fastapi_logs"]
source = """
# -------- message --------
.message, _ = to_string(.message)

# -------- level (prefer .level, fallback .levelname) --------
lvl, _  = to_string(.level)
lnm, _  = to_string(.levelname)
if lvl != null && lvl != "" {
  .level = upcase(lvl)
} else if lnm != null && lnm != "" {
  .level = upcase(lnm)
} else {
  .level = "INFO"
}

# -------- direct fields from FastAPI payload --------
tid,   _ = to_string(.task_id)
hk,    _ = to_string(.hotkey)
mdl,   _ = to_string(.model)
tt,    _ = to_string(.task_type)
cname, _ = to_string(.container_name)
cid,   _ = to_string(.container_id)
svc,   _ = to_string(.service_name)
rid,   _ = to_string(.request_id)
stage, _ = to_string(.docker_stage)

.task_id        = if tid   != null && tid   != "" { tid }   else { "unknown" }
.hotkey         = if hk    != null && hk    != "" { hk }    else { "unknown" }
.model          = if mdl   != null && mdl   != "" { mdl }   else { "unknown" }
.task_type      = if tt    != null && tt    != "" { tt }    else { "app" }
.container_name = if cname != null && cname != "" { cname } else if svc != null && svc != "" { svc } else { "fastapi" }
.container_id   = if cid   != null && cid   != "" { cid }   else if rid != null && rid != "" { rid } else { "fastapi-host" }
.docker_stage   = if stage != null && stage != "" { stage } else { "app" }

# -------- timestamp: accept epoch ms if plausible, else now() --------
ts_ms, _ = to_int(.timestamp)
if ts_ms != null && ts_ms > 1_600_000_000_000 && ts_ms < 4_100_000_000_000 {
  .timestamp = from_unix_timestamp(ts_ms, unit: "milliseconds") ?? now()
} else {
  .timestamp = now()
}

.count = 1
"""

# -------------------------
# Sinks
# -------------------------
[sinks.loki]
type = "loki"
inputs = ["parse_logs", "normalize_fastapi"]
endpoint = "${LOKI_ENDPOINT}"
auth.strategy = "basic"
auth.user = "${LOKI_USERNAME}"
auth.password = "${LOKI_PASSWORD}"
encoding.codec = "text"
batch.timeout_secs = 10
batch.max_bytes = 1048576
request.timeout_secs = 30
request.retry_attempts = 3
request.retry_initial_backoff_secs = 1
tls.verify_certificate = false


labels.job = "docker-training-containers"
labels.task_id = "{{ task_id }}"
labels.hotkey = "{{ hotkey }}"
labels.container_name = "{{ container_name }}"
labels.container_id = "{{ container_id }}"
labels.task_type = "{{ task_type }}"
labels.model = "{{ model }}"

# Prometheus exporter (Vector internal metrics)
[sinks.prometheus]
type = "prometheus_exporter"
inputs = ["internal_metrics"]
address = "0.0.0.0:9090"

default_namespace = "vector"
